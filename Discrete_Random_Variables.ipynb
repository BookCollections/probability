{
 "metadata": {
  "name": "Discrete_Random_Variables"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Discrete Random Variable**\n",
      "\n",
      "A **random variable** is a real-valued function of a probabilistic sample space. It is **discrete** if it's range is is *finite* or countably infinite, i.e. if a one-to-one correspondance can be created between it's range and the positive integers.\n",
      "\n",
      "A discrete random variable has an associated **probability mass function** (PMF) (aka probability distribution function) that gives the probability of each range value for the random variable. If *x* is any real number, the **probability mass** of *x* is the probability of the event $\\left\\\\{X=x\\right\\\\}\\hspace{1pt}$ consisting of all outcomes that give rise to the value *x* for *X* and is denoted\n",
      "\n",
      "$$p_X\\left(x\\right) = P\\left(\\left\\\\{X=x\\right\\\\}\\right)$$\n",
      "\n",
      "The PMF of a random variable *X* can be calculated as follows:\n",
      "\n",
      "For each possible value *x* of *X*:\n",
      "\n",
      "1. Collect all possible disjoint events in $\\Omega\\hspace{1pt}$ that give rise to the event $\\left\\\\{X=x\\right\\\\}\\hspace{1pt}$\n",
      "\n",
      "2. Add their probabilities to obtain $p_X\\left(x\\right)$\n",
      "\n",
      "3. Repeat for all *x*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Functions of Random Variables**\n",
      "\n",
      "If $Y=g\\left(X\\right)\\hspace{1pt}$ is a function of a random variable *X*, then *Y* is also a random variable. If *X* is discrete with PMF $p_X\\hspace{1pt}$, then *Y* is also discrete and its PMF is \n",
      "\n",
      "$$p_Y\\left(y\\right) = \\sum_{\\\\{x \\hspace{1pt}\\vert \\hspace{1pt} g\\left(x\\right)=y\\\\}} p_x\\left(x\\right)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Expectation (Mean)**\n",
      "\n",
      "The **expected** value, or mean, of a random variable *X* with PMF $p_X\\hspace{1pt}$ is defined as\n",
      "\n",
      "$$E\\left[X\\right] = \\sum_x x p_X\\left(x\\right)$$\n",
      "\n",
      "Note that the expectation is well-defined only if \n",
      "\n",
      "$$\\sum_x \\left| x \\right| p_X \\left(x\\right) \\lt \\infty$$\n",
      "\n",
      "This fails to hold for certain distributions. For example, consider a power law PMF of the form $p_X\\left(x\\right) = \\frac{\\alpha}{x^{\\alpha+1}}\\hspace{1pt}$ with $\\alpha\\le1$. Then the expected value is a divergent [p-series](http://en.wikipedia.org/wiki/Harmonic_series_(mathematics)#P-series).\n",
      "\n",
      "**Expected Value of Functions of Random Variables**\n",
      "\n",
      "Let *X* be a random variable with PMF $p_X\\hspace{1pt}$ and let $g\\left(X\\right)\\hspace{1pt}$ be a function of *X*. Then the expected value of the random variable $Y=g\\left(X\\right)\\hspace{1pt}$ is \n",
      "\n",
      "$$E\\left[Y\\right]=E\\left[g\\left(X\\right)\\right] = \\sum_x g\\left(x\\right) p_X \\left(x\\right)$$\n",
      "\n",
      "Note that unless $g\\left(X\\right)\\hspace{1pt}$ is a linear function, it is **not** generally true that $E\\left[g\\left(X\\right)\\right] = g\\left(E\\left[X\\right]\\right)\\hspace{1pt}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Higher Order Moments**\n",
      "\n",
      "The expected value is special case of the more general notion of the *n***th moment** of a random variable *X*, defined as\n",
      "\n",
      "$$E\\left[X\\right] = \\sum_x x^n p_X\\left(x\\right)$$\n",
      "\n",
      "where again this is only well defined if \n",
      "\n",
      "$$\\sum_x \\left| x^n \\right| p_X \\left(x\\right) \\lt \\infty$$\n",
      "\n",
      "As with the mean, this condition can fail for certain distributions. Consider the power law PMF described previously. All moments, *m*, such that $m\\ge\\alpha\\hspace{1pt}$ fail to satisfy this condition."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Variance**\n",
      "\n",
      "The **variance** of a random variable, denoted $var\\left(X\\right)\\hspace{1pt}$ is defined as the expected value of the random variable $\\left(X - E\\left[X\\right]\\right)^2\\hspace{1pt}$ and the following identities hold\n",
      "\n",
      "$$\\begin{eqnarray}var\\left(X\\right) &=& E\\left[\\left(X-E\\left[X\\right]\\right)^2\\right] \\cr\n",
      "        &=& \\sum_x\\left(x-E\\left[X\\right]\\right)^2 p_X\\left(x\\right) \\cr\n",
      "        &=& E\\left[X^2\\right] - \\left(E\\left[X\\right]\\right)^2\n",
      "\\end{eqnarray}$$\n",
      "\n",
      "The variance is a measure of the expected value of the square of difference between an arbitrary observation of a RV and the mean of that RV.  \n",
      "\n",
      "The **standard deviation**, $\\sigma_X\\hspace{1pt}$, is defined as the square root of the variance.\n",
      "\n",
      "**Linear Function of a Random Variable**\n",
      "\n",
      "Let *X* be a random variable and let $Y=aX+b\\hspace{1pt}$ for scalars *a* and *b*. Then\n",
      "\n",
      "$$E\\left[Y\\right] = a E\\left[X\\right] + b$$\n",
      "\n",
      "and \n",
      "\n",
      "$$var\\left(Y\\right) = a^2var\\left(X\\right)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Joint PMFS of Multiple Random Variables**\n",
      "\n",
      "Consider two discrete random variables *X* and *Y*. The probabilities of the pairs $\\left(x,y\\right)\\hspace{1pt}$ that the *X* and *Y* can take are described by the **joint PMF** denoted $p_{X,Y}$\n",
      "\n",
      "$$p_{X,Y}\\left(x,y\\right) = P\\left(X=x,Y=y\\right)$$\n",
      "\n",
      "From the joint PMF, the PMF of *X* or *Y* can be obtained as\n",
      "\n",
      "$$p_X\\left(x\\right) = \\sum_y p_{X,Y}\\left(x,y\\right) \\quad p_Y\\left(y\\right) = \\sum_x p_{X,Y}\\left(x,y\\right)$$\n",
      "\n",
      "where here $p_X\\hspace{1pt}$ and $p_Y\\hspace{1pt}$ are referred to as the **marginal PMFs**, though their meaning and values are exactly the same as the standard PMF of the single variables $X$ and $Y$. The term *marginal* simply distinguishes them from the full joint PMF.\n",
      "\n",
      "Naturally, these notions can be extended to any number of discrete random variables $X_1, \\ldots, X_n\\hspace{1pt}$ with joint PMF\n",
      "\n",
      "$$p_{X_1,\\ldots,X_n}\\left(x_1,\\ldots,x_n\\right) = P\\left(X_1=x_1,\\ldots,X_n=x_n\\right)$$\n",
      "\n",
      "For any $X_i\\hspace{1pt}$ let $X_1, \\ldots, X_{n-1}$ be the remaining random variables from $X_1, \\ldots, X_n$ the PMF of $X_i\\hspace{1pt}$ is \n",
      "\n",
      "$$p_{X_i}\\left(x\\right) = \\sum_{x_1}\\ldots\\sum_{x_{n-1}}p_{X_1\\ldots,X_n}\\left(x_1,\\ldots,x_{n-1}\\right)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Functions of Multiple Random Variables**\n",
      "A function $Z=g\\left(X,Y\\right)\\hspace{1pt}$ of the random variables *X* and *Y* is a random varibale with PMF\n",
      "\n",
      "$$p_Z\\left(z\\right) = \\sum_{\\left\\\\{ \\left(x,y\\right) \\vert g\\left(x,y\\right)=z\\right\\\\}} p_{X,Y}\\left(x,y\\right)$$\n",
      "\n",
      "The expected value of *Z* is\n",
      "\n",
      "$$E\\left[g\\left(X,Y\\right)\\right] = \\sum_x\\sum_y g\\left(x,y\\right) p_{X,Y}\\left(x,y\\right) $$\n",
      "\n",
      "These notions can be extended to any number of discrete random variables. Let $\\bar{X_s} = \\left\\\\{X_1,\\ldots,X_n\\right\\\\}\\hspace{1pt}$ be a set of discrete random variables with joint PMF $p_{\\bar{X_s}}\\hspace{1pt}$. Let *Z* be the random variable defined by $Z=g\\left(\\bar{X_s}\\right)\\hspace{1pt}$, then *Z* has PMF\n",
      "\n",
      "$$p_Z(z) = \\sum_{\\left\\\\{\\left(x_1,\\ldots,x_n\\right) \\hspace{2pt}\\vert \\hspace{2pt} g\\left(x_1,\\ldots,x_n\\right)=z\\right\\\\}} p_{\\bar{X_s}}\\left(x_1,\\ldots, x_n\\right)$$\n",
      "\n",
      "and the expected value of *Z* is\n",
      "\n",
      "$$E\\left[Z\\right] = E\\left[g\\left(\\bar{X_s}\\right)\\right] = \\sum_{x_1}\\ldots\\sum_{x_n}g\\left(x_1,\\ldots,x_n\\right)p_{\\bar{X_s\n",
      "}}\\left(x_1,\\ldots,x_n\\right)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Conditioning a RV on another RV**\n",
      "\n",
      "Let *X* and *Y* be two random variables. The **conditional PMF** of *X* given *Y* is \n",
      "\n",
      "$$p_{X\\vert Y} \\left(x \\vert y \\right) = \n",
      "\\frac {P\\left( X=x,Y=y \\right)} {P\\left( Y=y \\right)} = \n",
      "\\frac{P \\left( \\left\\\\{ X=x \\right\\\\} \\cap \\left\\\\{ Y=y \\right\\\\} \\right)} {P\\left( \\left\\\\{Y=y\\right\\\\} \\right)}\n",
      "= \\frac{p_{X,Y}\\left(x,y\\right)}{p_Y\\left(y\\right)}$$\n",
      "\n",
      "The conditional probability is itself a valid probability model and satisfies\n",
      "\n",
      "$$\\sum_x p_{X\\vert Y} \\left(x\\vert y\\right) = 1$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Conditional Expectation**\n",
      "\n",
      "Let *X* and *Y* be random variables. The conditional expectation of *X* given *Y=y* is \n",
      "\n",
      "$$E\\left[X\\vert Y =y\\right] = \\sum_x x p_{X \\vert Y}\\left(x \\vert y\\right)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Total Expectation Theorem**\n",
      "If $A_1,\\ldots,A_n\\hspace{1pt}$ is a disjoint partition of the sample space with $P\\left(A_i\\right)>0$ for all *i* then\n",
      "\n",
      "$$E[X] = \\sum_i^n P\\left(A_i\\right) E\\left[X\\vert A_i \\right]$$\n",
      "\n",
      "In words, this states that expected value of *X* is a weighted average of the expected values of *X* under the events $A_i\\hspace{1pt}$ where the weights are the probability of the events $A_i\\hspace{1pt}$ provided they form a partition of the sample space.\n",
      "\n",
      "For any event *B* with $P\\left(A_i \\cap B\\right) > 0 \\hspace{1pt}$ for all *i*, we have\n",
      "\n",
      "$$E\\left[X\\vert B \\right] = \\sum_{i=1}^n P \\left( A_i \\vert B \\right) E \\left[X \\vert A_i \\cap B \\right]$$\n",
      "\n",
      "where this has a similar interpretation as a weighted average of the expected values of *X* under the events  $A_i \\cap B\\hspace{1pt}$. Finally, we also have\n",
      "\n",
      "$$ E \\left[X \\right] = \\sum_y p_Y\\left( y \\right) E\\left[X \\vert Y=y \\right]$$\n",
      "\n",
      "which can also be intrepreted as stating that the expected value of *X* is a weighted average of the conditional expectation of *X* conditioned on *Y* where the weights are the PMF of *Y*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Independence of Random Variables**\n",
      "\n",
      "Two random variables *X* and *Y* are **independent** if\n",
      "\n",
      "$$p_{X,Y} \\left(x,y\\right) = p_X \\left(x\\right) p_Y \\left(y\\right) \\quad \\forall \\hspace{2pt} x,y$$\n",
      "\n",
      "which is equivalent to requiring that the events $\\left\\\\{X=x\\right\\\\}\\hspace{1pt}$ and $\\left\\\\{Y=y\\right\\\\}\\hspace{1pt}$ are independent **for all** combinations of *x* and *y*. This concept can be extended to any number of random variables, that is the set of random variables $X_1,\\ldots,X_n\\hspace{1pt}$ are independent if\n",
      "\n",
      "$$P_{X_1,\\ldots,X_n} \\left(x_1,\\ldots,x_n\\right) = p_{X_1}\\left(x_1\\right) \\ldots p_{X_n}\\left(x_n\\right) \\quad \\forall \\hspace{2pt} x_1,\\ldots,x_n$$\n",
      "\n",
      "Notice that unlike the case of independent **events** we do not explicitly require the sub-conditions of independence of all the different combinations of the random variables. In fact, these conditions are embedded in the given condition because it must hold for all $x_1,\\ldots,x_n\\hspace{1pt}$.\n",
      "\n",
      "*X* and *Y* are said to **conditionally independent** given an event *A* if\n",
      "\n",
      "$$p_{X,Y \\vert A} \\left(x,y\\right) = p_{X\\vert A}\\left(x\\right) p_{Y \\vert A}\\left(y\\right) \\quad \\forall \\hspace{2pt} x,y$$\n",
      "\n",
      "If $X_1,\\ldots,X_n$ are independent\n",
      "\n",
      "$$var\\left(X_1 + \\ldots + X_n\\right) = var\\left(X_1\\right) + \\ldots var\\left(X_n\\right)$$\n",
      "\n",
      "i.e. the variance of the sum of **independent** random variables is equal to the sum of the variances."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}